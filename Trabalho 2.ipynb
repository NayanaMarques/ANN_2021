{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_02_V_4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NayanaMarques/ANN_2021/blob/master/Trabalho%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mm8oeR4bDFi"
      },
      "source": [
        "#Projeto 2: Redes Neurais - Professor Ubirajara Filho\n",
        "#Nayana G. Marques Silva\n",
        "\n",
        "#Definição de bibliotecas\n",
        "\n",
        "from matplotlib import pyplot as plt #plotar as imagens\n",
        "import pandas as pd #biblioteca para manipulação de arquivos\n",
        "import os\n",
        "import cv2 #biblioteca para processamento de imagem\n",
        "import random #biblioteca para gerar numeros aleatorios\n",
        "import numpy as np #biblioteca numérica Phyton\n",
        "import zipfile #biblioteca para manipular ZIP\n",
        "\n",
        "from sklearn.svm import SVC #biblioteca de Support Vector Machine para ajuste e seleção de modelos\n",
        "from sklearn import preprocessing #biblioteca para normalizar dados\n",
        "from sklearn.model_selection import train_test_split #biblioteca para separar dados em treino e teste\n",
        "from sklearn.metrics import classification_report #biblioteca para uso da matriz confusao\n",
        "from keras.models import Sequential #biblioteca para criar lista simples de camadas de entrada única e saída única \n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization # biblioteca para linguagens de deep larning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOSkBMletVYx",
        "outputId": "13c83598-bb0e-4f67-c541-5fc5773a627a"
      },
      "source": [
        "!git clone https://github.com/NayanaMarques/ANN_2021\n",
        "%cd ANN_2021"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ANN_2021'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 144 (delta 70), reused 8 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (144/144), 173.57 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n",
            "/content/ANN_2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMKeneKzuD3X"
      },
      "source": [
        "Fauna =['CORUJA_1.zip','CORUJA_2.zip','EMA_1.zip','EMA_2.zip','VEADO-CAMPEIRO_1.zip','VEADO-CAMPEIRO_2.zip','VEADO-CAMPEIRO_3.zip']\n",
        "\n",
        "Fauna_name=[] #lista com o nome dos arquivos\n",
        "x_grayscale=[] #lista para armazenamento de imagens em escalas de cinza\n",
        "x_original = [] # lista  para armazenar as imagens originais\n",
        "#\n",
        "#Leitura dos arquivos .zip\n",
        "for FILE in Fauna:\n",
        "  file_name = zipfile.ZipFile(FILE, 'r')\n",
        "#\n",
        "#Extração dos arquivos do zip\n",
        "  file_name.extractall()\n",
        "  with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "      for name in f.namelist():\n",
        "          Fauna_name.append(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kliEBpwiwAZQ",
        "outputId": "66c3cc36-0767-4416-952e-a26b5aa9228a"
      },
      "source": [
        "print(Fauna_name) #teste verificação"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CORUJA_1/', 'CORUJA_1/coruja buraqueira.JPG', 'CORUJA_1/Coruja_1309.JPG', 'CORUJA_1/Coruja_1909 1.jpg', 'CORUJA_1/Coruja_9289.JPG', 'CORUJA_1/Coruja_9290.JPG', 'CORUJA_1/Coruja_9292.JPG', 'CORUJA_2/', 'CORUJA_2/Coruja03892.JPG', 'CORUJA_2/Coruja03904.JPG', 'CORUJA_2/Coruja03906.JPG', 'CORUJA_2/Coruja03908.JPG', 'CORUJA_2/Coruja3909.JPG', 'EMA_1/', 'EMA_1/Ema_1585.JPG', 'EMA_1/Ema_1595.JPG', 'EMA_1/Ema_1597.JPG', 'EMA_1/Ema_1599.JPG', 'EMA_1/Ema_1637.JPG', 'EMA_2/', 'EMA_2/Ema_1804.JPG', 'EMA_2/Ema_1807.JPG', 'EMA_2/Ema_1809.JPG', 'EMA_2/Ema_1815.JPG', 'EMA_2/Ema_1817.JPG', 'VEADO-CAMPEIRO_1/', 'VEADO-CAMPEIRO_1/Veado_2125.JPG', 'VEADO-CAMPEIRO_1/Veado_2155.JPG', 'VEADO-CAMPEIRO_1/Veado_2158.JPG', 'VEADO-CAMPEIRO_2/', 'VEADO-CAMPEIRO_2/Veado_2169.JPG', 'VEADO-CAMPEIRO_2/Veado_2174.JPG', 'VEADO-CAMPEIRO_2/Veado_9372.JPG', 'VEADO-CAMPEIRO_2/Veado_9376.JPG', 'VEADO-CAMPEIRO_3/', 'VEADO-CAMPEIRO_3/Veado_1499.JPG', 'VEADO-CAMPEIRO_3/Veado_1514.JPG', 'VEADO-CAMPEIRO_3/Veado_2164.JPG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1nLNSdFwS-7"
      },
      "source": [
        "y_names = [] #lista em branco para armazenar 3 primeiras letras do nome dos arquivos\n",
        "for yy in Fauna_name:\n",
        "  name = yy[0]+yy[1]+yy[2] #[0][1][2] --> salvando primeira, segunda e terceira letras\n",
        "  y_names.append(name) #registrar as  3 primeiras letras identificadas"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QyB_sKMzNLP"
      },
      "source": [
        "unique_list = [] #lista para armazenar informações dos arquivos.zip\n",
        "for yy in y_names:\n",
        "  if yy not in unique_list:\n",
        "    unique_list.append(yy)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wfc8DAlzcuG",
        "outputId": "197dace9-0c8a-478f-8fb2-fd47c9858633"
      },
      "source": [
        "print(unique_list) #teste de verificação"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['COR', 'EMA', 'VEA']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l8y2FzRzlvH"
      },
      "source": [
        "n = len(unique_list) #retornar quantidade de elemntos da lista unique_list\n",
        "y = [] #lista para armazenar informações \n",
        "for yy in y_names:\n",
        "  for i in range(n):\n",
        "    if(yy == unique_list[i]):\n",
        "      y.append(i)  #registrar as infomações em y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRfu6Agpz-Jr"
      },
      "source": [
        "DATASET_SIZE = len(y_names) #Retorna a quantidade de elementos de y_names e armazena em DATASET_SIZE\n",
        "Ind = range(DATASET_SIZE)\n",
        "Fauna_Size = 100 #Definir o tamanho das imagens\n",
        "num_range = DATASET_SIZE #Armazenar informações reportadas"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctXwTrLj0lPR"
      },
      "source": [
        "#teste com 20% dos dados, aleatório (random_state)\n",
        "Ind_train, Ind_test= train_test_split(Ind,test_size=0.20, shuffle=True, random_state=3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCbfYHrP00Ja",
        "outputId": "d2451511-5e07-4a32-e436-3af96f06d572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "X_train = [] \n",
        "Y_train = []\n",
        "\n",
        "for II in Ind_train:\n",
        "  name = Fauna_name[II]\n",
        "  X_train.append(cv2.resize(cv2.imread(name),(Fauna_Size,Fauna_Size))) #alteração da resolução das imagens\n",
        "  Y_train.append(y[II]) #armazenamento"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-11e9c7eadbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mII\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mInd_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFauna_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mII\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFauna_Size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFauna_Size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#alteração da resolução das imagens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mII\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#armazenamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRha2-P1QwM"
      },
      "source": [
        "X_test= []\n",
        "Y_test = []\n",
        "\n",
        "i =0\n",
        "for II in Ind_test:\n",
        "  name = Fauna_name[II]\n",
        "  X_test.append(cv2.resize(cv2.imread(name),(Fauna_Size,Fauna_Size))) #alteração da resolução das imagens\n",
        "  Y_test.append(y[II]) #armazenamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V56wSIkA1sFo"
      },
      "source": [
        "num = len(Y_train)\n",
        "plt.figure(figsize=(10, 10)) #plotar as imagens size 10 x 10\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1) #plotar imagens em 3 colunas e 3 linhas\n",
        "  kk = int(random.randrange(num))\n",
        "  RGB_img = cv2.cvtColor(X_train[kk], cv2.COLOR_BGR2RGB) #converter imagens BGR em RGB \n",
        "  plt.imshow(RGB_img) #plotar imagens\n",
        "  plt.title(Y_train[kk]) #plotar imagens\n",
        "# O comando plt.title indica que títulos\n",
        "  plt.axis(\"off\") #sem legenda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1_pLiFs3CbY"
      },
      "source": [
        "num #retorna quantidade de arquivos existentes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D_pbxPb3hu6"
      },
      "source": [
        "num = len(Y_test)\n",
        "plt.figure(figsize=(10, 10)) #plotar imagens size 10 x 10\n",
        "for i in range(9): \n",
        "  ax = plt.subplot(3, 3, i + 1) #plotar imagens em 3 colunas e 3 linhas\n",
        "  kk = int(random.randrange(num)) #retornar incrementos específicos de números aleatórios\n",
        "  RGB_img = cv2.cvtColor(X_test[kk], cv2.COLOR_BGR2RGB) #converter imagens BGR em RGB\n",
        "  plt.imshow(RGB_img) #plotar imagens\n",
        "  plt.title(Y_test[kk]) #plotar títulos\n",
        "  plt.axis(\"off\") #sem legenda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVcO94BQ4n7h"
      },
      "source": [
        "X_new = []\n",
        "\n",
        "for XX in X_train:\n",
        "  X_new.append(XX)\n",
        "print(XX)\n",
        "X_train = X_new.copy()\n",
        "\n",
        "X_new = []\n",
        "for XX in X_test:\n",
        "  X_new.append(XX)\n",
        "X_test = X_new.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3SRzZlb5Sg9"
      },
      "source": [
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K)) #matriz N x K de zeros\n",
        "  I[np.arange(N), Y] = 1 #Retorna valores uniformemente espaçados\n",
        "  return I"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqcpenNc5u05"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train) \n",
        "K = len(set(Y_train))\n",
        "X_train = X_train /255.0 #divisão por 255 é para evitar a saturação (cores são preenchimentos de 0 a 255)\n",
        "Y_train = Y_train.astype(np.int32) #garantir dados fiquem escalonados\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test /255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37fRkLUb6qk-"
      },
      "source": [
        "model = Sequential() #modelo sequencia simples de camadas / construída uma CNN (Convolutional neural network)\n",
        "model.add(Conv2D(input_shape=(Fauna_Size, Fauna_Size, 3), filters=32, kernel_size=(3, 3))) #imagens coloridas, 32 filtros, kernel_size definido\n",
        "model.add(BatchNormalization()) #normalização\n",
        "model.add(Activation('tanh')) #função de ativação: tangente hiperbólica\n",
        "model.add(MaxPooling2D()) #redução do tamanho da foto\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('tanh'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('tanh'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten()) #redução para 1 dimensão\n",
        "model.add(Dense(units=200)) #função de ativação em conjunto com os dados de entrada e pesos (200 unidades)\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dropout(0.3)) #prevenção de sobre-ajustamento de dados\n",
        "model.add(Dense(units=100)) #função de ativação em conjunto com os dados de entrada e pesos (100 unidades)\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))  #forma multidimensional generalizada da função logística (ativação)\n",
        "\n",
        "model.compile( #compilação dos dados\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_5Bp1wn9l9u"
      },
      "source": [
        "r = model.fit(X_train, Y_train, validation_data = (X_test,Y_test), epochs=2, batch_size=16)\n",
        "print(\"Returned:\", r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZcPPrgU-flr"
      },
      "source": [
        "# Plotagem dos gráficos para verificação de convergência - acurácia\n",
        "plt.plot(r.history['accuracy'], label='acurácia')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-99bGRT-wEm"
      },
      "source": [
        "# Plotagem dos gráficos para verificação de convergência - perdas\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}